{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b78af2c-9c54-427c-84e2-4f2f8b7ee4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, precision_recall_curve,roc_curve,log_loss,balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "\n",
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "96e8be08-76dc-4ac6-a4cf-baf45543e322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/data/ab01/standard_dataset/processed_dataset/CM000/CM000_train_clone-pass_germ-pass.tsv'),\n",
       " PosixPath('/data/ab01/standard_dataset/processed_dataset/CM001/CM001_train_clone-pass_germ-pass.tsv'),\n",
       " PosixPath('/data/ab01/standard_dataset/processed_dataset/CM002/CM002_train_clone-pass_germ-pass.tsv'),\n",
       " PosixPath('/data/ab01/standard_dataset/processed_dataset/CM003/CM003_train_clone-pass_germ-pass.tsv')]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据目录\n",
    "root = Path('/data/ab01/standard_dataset/processed_dataset')\n",
    "train_data_paths = [root/f'CM00{i}'/f'CM00{i}_train_clone-pass_germ-pass.tsv' for i in [0,1,2,3]]\n",
    "valid_data_paths = [root/f'CM00{i}'/f'CM00{i}_valid_clone-pass.tsv' for i in [1,2,3]]\n",
    "\n",
    "train_data_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1593a306-41b7-406b-a243-a944fb676b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/data/ab01/standard_dataset/processed_dataset/CM001/CM001_valid_clone-pass.tsv'),\n",
       " PosixPath('/data/ab01/standard_dataset/processed_dataset/CM002/CM002_valid_clone-pass.tsv'),\n",
       " PosixPath('/data/ab01/standard_dataset/processed_dataset/CM003/CM003_valid_clone-pass.tsv')]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5629325b-3819-47a8-94f3-45e587f694b3",
   "metadata": {},
   "source": [
    "## clonal lineage\n",
    "> Reference: https://www.pnas.org/cgi/doi/10.1073/pnas.1814213116)\n",
    "### step1\n",
    "group sequences having the same V and J germline genes and CDR3 length\n",
    "\n",
    "### setp2\n",
    "<!-- Within each group, performing single-linkage clustering on the CDR3 sequence using a cutoff of 90% sequence identity -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc3a66e-f700-4c86-aebe-1c5100efdfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa-cdist: 每一条序列到该进化树共有序列(consensus sequence)的距离，通过hamming distance进行测量——数值越小表示亲和力越强。间接反应了我们之前观测到的特异性clonotype里，末端进化支长度普遍较短。\n",
    "dist_mrca: 0.03358314574722221\n",
    "leaf_bl: 0.026341668088888884\n",
    "nuc-lbi: 0.006910531404293908\n",
    "nuc-lbr: 内部节点到其所有外部节点的进化支总长度÷该节点到进化树的根的进化支总长度。该参数可用来定量一个增强亲和力的变异在这个节点产生的概率，因为该变异会增强该节点后代的适应度——所以该数值越大表示其适应度越强。\n",
    "sackin_idx: 10.527777777777779"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0dbbcf89-32d5-4328-85e2-2b50079ba2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in train_data_paths:\n",
    "    df0 = pd.read_csv(file, sep='\\t')\n",
    "    df0['cdr3_seq_len'] = df0['cdr3'].apply(lambda x: len(x))\n",
    "    df0['junction_seq_len'] = df0['cdr3'].apply(lambda x: len(x))\n",
    "    # df0['germline_v_call'] = df0['v_call'].apply(lambda x: x.split(',')[0] if x else None)\n",
    "    # df0['germline_j_call'] = df0['j_call'].apply(lambda x: x.split(',')[0] if x else None)\n",
    "    df0['v_gene_name'] = df0['germline_v_call'].apply(lambda x: x.split('*')[0] if x else None)\n",
    "    df0['j_gene_name'] = df0['germline_j_call'].apply(lambda x: x.split('*')[0] if x else None)\n",
    "    \n",
    "    # grouped = df0.groupby(by=['v_germline_alignment', 'j_germline_alignment', 'cdr3_len'])\n",
    "    # grouped2 = df0.groupby(by=['v_gene_name', 'j_gene_name', 'cdr3_len'])\n",
    "    # df0['group_id_by_germline_seq'] = None\n",
    "    \n",
    "    # group_id = 0\n",
    "    # for key, idx in grouped2.groups.items():\n",
    "    #     group_id+=1\n",
    "    #     df0.loc[idx, 'group_id_by_germline_seq'] = group_id\n",
    "    \n",
    "    df0 = df0.where(pd.notnull(df0), None)\n",
    "    with open(f'data/test/{file.name}', 'w') as f:\n",
    "        f_csv = csv.writer(f, delimiter='\\t')\n",
    "        f_csv.writerow(df0.columns)\n",
    "        f_csv.writerows(df0.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ab2a06e1-ecfc-4501-9c44-f07c1e297c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in valid_data_paths:\n",
    "    df0 = pd.read_csv(file, sep='\\t')\n",
    "    df0['cdr3_seq_len'] = df0['cdr3'].apply(lambda x: len(x))\n",
    "    df0['junction_seq_len'] = df0['cdr3'].apply(lambda x: len(x))\n",
    "    df0['germline_v_call'] = df0['v_call'].apply(lambda x: x.split(',')[0] if x else None)\n",
    "    df0['germline_j_call'] = df0['j_call'].apply(lambda x: x.split(',')[0] if x else None)\n",
    "    df0['v_gene_name'] = df0['germline_v_call'].apply(lambda x: x.split('*')[0] if x else None)\n",
    "    df0['j_gene_name'] = df0['germline_j_call'].apply(lambda x: x.split('*')[0] if x else None)\n",
    "    \n",
    "    # grouped = df0.groupby(by=['v_germline_alignment', 'j_germline_alignment', 'cdr3_len'])\n",
    "#     grouped2 = df0.groupby(by=['germline_v_call_without_allele', 'germline_j_call_without_allele', 'cdr3_len'])\n",
    "#     df0['group_id_by_germline_seq'] = None\n",
    "    \n",
    "#     group_id = 0\n",
    "#     for key, idx in grouped2.groups.items():\n",
    "#         group_id+=1\n",
    "#         df0.loc[idx, 'group_id_by_germline_seq'] = group_id\n",
    "    \n",
    "    df0 = df0.where(pd.notnull(df0), None)\n",
    "    with open(f'data/test/{file.name}', 'w') as f:\n",
    "        f_csv = csv.writer(f, delimiter='\\t')\n",
    "        f_csv.writerow(df0.columns)\n",
    "        f_csv.writerows(df0.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "68f7a271-b313-461f-a60f-6e9e70bebc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_t = pd.read_csv('data/test/CM001_train_clone-pass_germ-pass.tsv', sep='\\t')\n",
    "df1_v = pd.read_csv('data/test/CM001_valid_clone-pass.tsv', sep='\\t')\n",
    "df1_all = pd.concat([df1_t.loc[:, ['sequence_id', 'cdr3_seq_len', 'v_gene_name', 'j_gene_name', 'clone_id']], df1_v.loc[:, ['sequence_id', 'cdr3_seq_len', 'v_gene_name', 'j_gene_name', 'clone_id']]], axis=0)\n",
    "# df1_all['clone_id_by_same_cdr3_len'] = None\n",
    "df1_all['clone_id_by_same_gene_name'] = None\n",
    "\n",
    "grouped = df1_all.groupby(by=['v_gene_name', 'j_gene_name', 'cdr3_seq_len'])\n",
    "group_id = 0\n",
    "for key, idx in grouped.groups.items():\n",
    "    group_id+=1\n",
    "    df1_all.loc[idx, 'clone_id_by_same_gene_name'] = group_id\n",
    "    \n",
    "df1_t = pd.merge(df1_t, df1_all.loc[:, ['sequence_id','clone_id_by_same_gene_name']], on='sequence_id', how='left')\n",
    "df1_v = pd.merge(df1_v, df1_all.loc[:, ['sequence_id','clone_id_by_same_gene_name']], on='sequence_id', how='left')\n",
    "\n",
    "df1_t = df1_t.where(pd.notnull(df1_t), None)\n",
    "with open('data/cluster_by_same_gene_name/CM001_train_clone-pass_germ-pass.tsv', 'w') as f:\n",
    "    f_csv = csv.writer(f, delimiter='\\t')\n",
    "    f_csv.writerow(df1_t.columns)\n",
    "    f_csv.writerows(df1_t.values)\n",
    "\n",
    "df1_v = df1_v.where(pd.notnull(df1_v), None)\n",
    "with open('data/cluster_by_same_gene_name/CM001_valid_clone-pass.tsv', 'w') as f:\n",
    "    f_csv = csv.writer(f, delimiter='\\t')\n",
    "    f_csv.writerow(df1_v.columns)\n",
    "    f_csv.writerows(df1_v.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ef051fba-8a97-418a-bbb4-0adfa401bae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_v['clone_id_by_same_gene_name'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b644e940-7c5f-4fca-bcee-0faea4351ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_t = pd.read_csv('data/test/CM002_train_clone-pass_germ-pass.tsv', sep='\\t')\n",
    "df2_v = pd.read_csv('data/test/CM002_valid_clone-pass.tsv', sep='\\t')\n",
    "df2_all = pd.concat([df2_t.loc[:, ['sequence_id', 'cdr3_seq_len', 'v_gene_name', 'j_gene_name', 'clone_id']], df2_v.loc[:, ['sequence_id', 'cdr3_seq_len', 'v_gene_name', 'j_gene_name', 'clone_id']]], axis=0)\n",
    "# df2_all['clone_id_by_same_cdr3_len'] = None\n",
    "df2_all['clone_id_by_same_gene_name'] = None\n",
    "\n",
    "grouped = df2_all.groupby(by=['v_gene_name', 'j_gene_name', 'cdr3_seq_len'])\n",
    "group_id = 0\n",
    "for key, idx in grouped.groups.items():\n",
    "    group_id+=2\n",
    "    df2_all.loc[idx, 'clone_id_by_same_gene_name'] = group_id\n",
    "    \n",
    "df2_t = pd.merge(df2_t, df2_all.loc[:, ['sequence_id','clone_id_by_same_gene_name']], on='sequence_id', how='left')\n",
    "df2_v = pd.merge(df2_v, df2_all.loc[:, ['sequence_id','clone_id_by_same_gene_name']], on='sequence_id', how='left')\n",
    "\n",
    "df2_t = df2_t.where(pd.notnull(df2_t), None)\n",
    "with open('data/cluster_by_same_gene_name/CM002_train_clone-pass_germ-pass.tsv', 'w') as f:\n",
    "    f_csv = csv.writer(f, delimiter='\\t')\n",
    "    f_csv.writerow(df2_t.columns)\n",
    "    f_csv.writerows(df2_t.values)\n",
    "\n",
    "df2_v = df2_v.where(pd.notnull(df2_v), None)\n",
    "with open('data/cluster_by_same_gene_name/CM002_valid_clone-pass.tsv', 'w') as f:\n",
    "    f_csv = csv.writer(f, delimiter='\\t')\n",
    "    f_csv.writerow(df2_v.columns)\n",
    "    f_csv.writerows(df2_v.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7d3590ef-becd-4521-97b9-05b7669ddb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_t = pd.read_csv('data/test/CM003_train_clone-pass_germ-pass.tsv', sep='\\t')\n",
    "df3_v = pd.read_csv('data/test/CM003_valid_clone-pass.tsv', sep='\\t')\n",
    "df3_all = pd.concat([df3_t.loc[:, ['sequence_id', 'cdr3_seq_len', 'v_gene_name', 'j_gene_name', 'clone_id']], df3_v.loc[:, ['sequence_id', 'cdr3_seq_len', 'v_gene_name', 'j_gene_name', 'clone_id']]], axis=0)\n",
    "# df3_all['clone_id_by_same_cdr3_len'] = None\n",
    "df3_all['clone_id_by_same_gene_name'] = None\n",
    "\n",
    "grouped = df3_all.groupby(by=['v_gene_name', 'j_gene_name', 'cdr3_seq_len'])\n",
    "group_id = 0\n",
    "for key, idx in grouped.groups.items():\n",
    "    group_id+=3\n",
    "    df3_all.loc[idx, 'clone_id_by_same_gene_name'] = group_id\n",
    "    \n",
    "df3_t = pd.merge(df3_t, df3_all.loc[:, ['sequence_id','clone_id_by_same_gene_name']], on='sequence_id', how='left')\n",
    "df3_v = pd.merge(df3_v, df3_all.loc[:, ['sequence_id','clone_id_by_same_gene_name']], on='sequence_id', how='left')\n",
    "\n",
    "df3_t = df3_t.where(pd.notnull(df3_t), None)\n",
    "with open('data/cluster_by_same_gene_name/CM003_train_clone-pass_germ-pass.tsv', 'w') as f:\n",
    "    f_csv = csv.writer(f, delimiter='\\t')\n",
    "    f_csv.writerow(df3_t.columns)\n",
    "    f_csv.writerows(df3_t.values)\n",
    "\n",
    "df3_v = df3_v.where(pd.notnull(df3_v), None)\n",
    "with open('data/cluster_by_same_gene_name/CM003_valid_clone-pass.tsv', 'w') as f:\n",
    "    f_csv = csv.writer(f, delimiter='\\t')\n",
    "    f_csv.writerow(df3_v.columns)\n",
    "    f_csv.writerows(df3_v.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8f9e8c82-fb1d-49e3-9410-3c4f27b66826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2059    1482\n",
       "2023     616\n",
       "1333     598\n",
       "928      458\n",
       "2081     342\n",
       "        ... \n",
       "235        1\n",
       "234        1\n",
       "1525       1\n",
       "232        1\n",
       "1988       1\n",
       "Name: clone_id, Length: 2186, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_all['clone_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "778d533a-bac9-4a2f-99ab-62e1e2ff2b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "948     1491\n",
       "2418     710\n",
       "2871     629\n",
       "354      616\n",
       "1443     484\n",
       "        ... \n",
       "3          1\n",
       "651        1\n",
       "444        1\n",
       "867        1\n",
       "1581       1\n",
       "Name: clone_id_by_same_gene_name, Length: 924, dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_all['clone_id_by_same_gene_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "cc5752ea-85ca-4516-8ce1-03379245631d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df0_t = pd.read_csv('data/test/CM000_train_clone-pass_germ-pass.tsv', sep='\\t')\n",
    "df0_t['clone_id_by_same_gene_name'] = None\n",
    "\n",
    "grouped = df0_t.groupby(by=['v_gene_name', 'j_gene_name', 'cdr3_seq_len'])\n",
    "group_id = 0\n",
    "for key, idx in grouped.groups.items():\n",
    "    group_id+=3\n",
    "    df0_t.loc[idx, 'clone_id_by_same_gene_name'] = group_id\n",
    "\n",
    "df0_t = df0_t.where(pd.notnull(df0_t), None)\n",
    "with open('data/cluster_by_same_gene_name/CM000_train_clone-pass_germ-pass.tsv', 'w') as f:\n",
    "    f_csv = csv.writer(f, delimiter='\\t')\n",
    "    f_csv.writerow(df0_t.columns)\n",
    "    f_csv.writerows(df0_t.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "669db3cd-7802-4248-84ee-53d0f949b0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "383    35\n",
       "403    32\n",
       "577    30\n",
       "517    27\n",
       "625    23\n",
       "       ..\n",
       "411     1\n",
       "414     1\n",
       "416     1\n",
       "417     1\n",
       "99      1\n",
       "Name: clone_id, Length: 876, dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0_t['clone_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a7115a76-ede5-4b3b-b462-0a0a101d39b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1113    39\n",
       "1179    38\n",
       "72      37\n",
       "1194    33\n",
       "51      33\n",
       "        ..\n",
       "387      1\n",
       "27       1\n",
       "483      1\n",
       "162      1\n",
       "270      1\n",
       "Name: clone_id_by_same_gene_name, Length: 511, dtype: int64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0_t['clone_id_by_same_gene_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a1acd9-f04d-4bc4-b6da-b578687bd90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算identity矩阵\n",
    "# for V gene allel\n",
    "\n",
    "\n",
    "# for J gene allel\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:automl] *",
   "language": "python",
   "name": "conda-env-automl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
